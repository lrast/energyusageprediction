{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7292407,"sourceType":"competition"},{"sourceId":7299768,"sourceType":"datasetVersion","datasetId":4234636}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bringing in other factors: part I","metadata":{}},{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom IPython.core.pylabtools import figsize\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:19:53.674996Z","iopub.execute_input":"2023-12-29T01:19:53.675724Z","iopub.status.idle":"2023-12-29T01:19:54.611415Z","shell.execute_reply.started":"2023-12-29T01:19:53.675634Z","shell.execute_reply":"2023-12-29T01:19:54.610344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"__context__ = 'kaggle'\n\nimport sys\n\nif __context__ == 'local':\n    trainDataLocation = '../data/train/'\n    libraryLocation = '..'\n    from public_timeseries_testing_util import MockApi\n    env = MockApi()\n    \n\nelif __context__ == 'kaggle':\n    trainDataLocation = '/kaggle/input/predict-energy-behavior-of-prosumers/'\n    libraryLocation = '/kaggle/input/'\n    import enefit\n    env = enefit.make_env()\n\niter_test = env.iter_test()\nsys.path.append(libraryLocation)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:19:54.613044Z","iopub.execute_input":"2023-12-29T01:19:54.613436Z","iopub.status.idle":"2023-12-29T01:19:54.625237Z","shell.execute_reply.started":"2023-12-29T01:19:54.613411Z","shell.execute_reply":"2023-12-29T01:19:54.623295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Processing the other datasets\n","metadata":{}},{"cell_type":"markdown","source":"### Notes and ideas from processing:\n\n1. historical weather is very useful for fitting the time-series baselines: we essentially want to remove the effect of weather when developing the time-dependent features.\n\n2. Small improvement: double check the data  \n","metadata":{}},{"cell_type":"code","source":"weather_forecast = pd.read_csv(trainDataLocation+'forecast_weather.csv')\nweather_historical = pd.read_csv(trainDataLocation+'historical_weather.csv')\n\nweather_historical['datetime'] = pd.to_datetime(weather_historical['datetime'])\nweather_historical = pl.from_pandas(weather_historical)\n\nweather_forecast['origin_datetime'] = pd.to_datetime(weather_forecast['origin_datetime'])\nweather_forecast['forecast_datetime'] = pd.to_datetime(weather_forecast['forecast_datetime'])\nweather_forecast = pl.from_pandas(weather_forecast)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:19:54.627135Z","iopub.execute_input":"2023-12-29T01:19:54.627847Z","iopub.status.idle":"2023-12-29T01:20:06.145957Z","shell.execute_reply.started":"2023-12-29T01:19:54.627809Z","shell.execute_reply":"2023-12-29T01:20:06.144781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather_historical.with_columns(\n                    pl.col('datetime').dt.date().alias('date')\n                 ).group_by('date'\n                 ).agg(mean_radiation=pl.col('direct_solar_radiation').mean()\n                 ).to_pandas(\n                 ).plot(x='date', y='mean_radiation', ax=None)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:20:06.148402Z","iopub.execute_input":"2023-12-29T01:20:06.148718Z","iopub.status.idle":"2023-12-29T01:20:06.52011Z","shell.execute_reply.started":"2023-12-29T01:20:06.148689Z","shell.execute_reply":"2023-12-29T01:20:06.518637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basic random forest model for production, linear model for consumption","metadata":{}},{"cell_type":"code","source":"from enefittools.data import format_dfs\n\ntrain = pd.read_csv(trainDataLocation+'train.csv')\nclient = pd.read_csv(trainDataLocation+'client.csv')\n\nweather_forecast = pd.read_csv(trainDataLocation+'forecast_weather.csv')\nweather_historical = pd.read_csv(trainDataLocation+'historical_weather.csv')\n\ntrain, client, weather_historical, weather_forecast = \\\n                format_dfs(target=train, client=client, weather_historical=weather_historical,\n                           weather_forecast=weather_forecast)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:20:06.521665Z","iopub.execute_input":"2023-12-29T01:20:06.521971Z","iopub.status.idle":"2023-12-29T01:20:18.946495Z","shell.execute_reply.started":"2023-12-29T01:20:06.521945Z","shell.execute_reply":"2023-12-29T01:20:18.945096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"solar = pd.read_csv(libraryLocation + '/enefittools/data/datasets/solar_data.csv')\nsolar['datetime'] = pd.to_datetime(solar['datetime'])\nsolar = pl.from_pandas(solar)\n\ndef make_features_random_forest(target, client, weather_forecast, solar=solar):\n    \"\"\" for the moment, we'll just use the forecast features \"\"\"\n\n    # note that this gives us two sets of features for each time: it is a daily 48hr forecast\n    weather_features = weather_forecast.with_columns(\n                                    pl.concat_str(pl.col('latitude'), pl.col('longitude'), separator=',').alias('location')\n                               ).pivot(\n                                        index=['forecast_datetime', 'hours_ahead'],\n                                        columns=['location'],\n                                        values=['temperature', 'direct_solar_radiation']\n                               ).drop('hours_ahead')\n    unit_features = target.drop('data_block_id'\n               ).join(\n                    client.drop('data_block_id'), \n                    left_on=['county', 'is_business', 'product_type', 'date_when_predicting'],\n                    right_on=['county', 'is_business', 'product_type', 'date'],\n                    how='inner'\n               )\n    return unit_features.join( weather_features, left_on='prediction_datetime', right_on='forecast_datetime', how='inner'\n                       ).join(\n                            solar, left_on='prediction_datetime', right_on='datetime', how='inner'\n                       ).drop(['target', 'prediction_datetime', 'date_when_predicting'])","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:20:18.948255Z","iopub.execute_input":"2023-12-29T01:20:18.948698Z","iopub.status.idle":"2023-12-29T01:20:18.991626Z","shell.execute_reply.started":"2023-12-29T01:20:18.948659Z","shell.execute_reply":"2023-12-29T01:20:18.99078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# process features\n\nfrom enefittools.features.regression_features import make_date_process, make_time_features\n\nconsumption_train = train.filter( pl.col('is_consumption') == 1).drop('is_consumption')\nproduction_train = train.filter( pl.col('is_consumption') == 0).drop('is_consumption')\n\ndates = make_date_process(train)\n\nconsumption_features = make_time_features( consumption_train, client, dates)\nproduction_features_RF = make_features_random_forest( production_train, client, weather_forecast)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:20:18.992675Z","iopub.execute_input":"2023-12-29T01:20:18.995136Z","iopub.status.idle":"2023-12-29T01:20:24.396205Z","shell.execute_reply.started":"2023-12-29T01:20:18.995103Z","shell.execute_reply":"2023-12-29T01:20:24.393789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from enefittools.data import split_production_consumption\ndates = make_date_process(train)\nfeatures = make_time_features( train, client, dates)\n\n(production_features, production_targets,\n     consumption_features, consumption_targets) = split_production_consumption(features, train)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:20:24.398113Z","iopub.execute_input":"2023-12-29T01:20:24.398487Z","iopub.status.idle":"2023-12-29T01:20:24.970348Z","shell.execute_reply.started":"2023-12-29T01:20:24.398454Z","shell.execute_reply":"2023-12-29T01:20:24.969529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# linear model\nfrom sklearn.pipeline import Pipeline\nfrom enefittools.models.linear_models import TimeseriesFeatures, ParallelLinearModels\n\nconsumption_pipeline = Pipeline([('time basis', TimeseriesFeatures()), \n                                 ('linear', ParallelLinearModels())])\nproduction_pipeline = Pipeline([('time basis', TimeseriesFeatures()), \n                                 ('linear', ParallelLinearModels())])\n\n# random forest model\n# to do: validation for hyper-parameters\nfrom sklearn.ensemble import RandomForestRegressor\nfrom enefittools.models import make_wrapped_model\n\n\nproduction_model = make_wrapped_model(RandomForestRegressor, max_samples=1000)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:20:24.971989Z","iopub.execute_input":"2023-12-29T01:20:24.972378Z","iopub.status.idle":"2023-12-29T01:20:25.099179Z","shell.execute_reply.started":"2023-12-29T01:20:24.97234Z","shell.execute_reply":"2023-12-29T01:20:25.097634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"production_model.fit(production_features_RF, production_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:20:25.10243Z","iopub.execute_input":"2023-12-29T01:20:25.102787Z","iopub.status.idle":"2023-12-29T01:20:53.886759Z","shell.execute_reply.started":"2023-12-29T01:20:25.102755Z","shell.execute_reply":"2023-12-29T01:20:53.885177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"consumption_pipeline.fit(consumption_features, consumption_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:20:53.888058Z","iopub.execute_input":"2023-12-29T01:20:53.888368Z","iopub.status.idle":"2023-12-29T01:21:11.146276Z","shell.execute_reply.started":"2023-12-29T01:20:53.888339Z","shell.execute_reply":"2023-12-29T01:21:11.145119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"production_pipeline.fit(production_features, production_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:21:11.150572Z","iopub.execute_input":"2023-12-29T01:21:11.151297Z","iopub.status.idle":"2023-12-29T01:21:28.26714Z","shell.execute_reply.started":"2023-12-29T01:21:11.151256Z","shell.execute_reply":"2023-12-29T01:21:28.266261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from enefittools.data.format_predictions import format_outputs\n\nfor (test, revealed_targets, client, weather_historical, weather_forecast,\n    electricityPrices, gasPrices, sample_prediction) in iter_test:\n\n    test, client, weather_forecast = format_dfs(target=test, client=client, weather_forecast=weather_forecast)\n    features = make_time_features(test, client, dates)\n\n    consumption_test = test.filter( pl.col('is_consumption') == 1).drop('is_consumption')\n    production_test = test.filter( pl.col('is_consumption') == 0).drop('is_consumption')\n    \n    consumption_features = make_time_features( consumption_test, client, dates)\n    production_features = make_time_features( production_test, client, dates)\n    production_features_rf = make_features_random_forest( production_test.drop('currently_scored'), client, weather_forecast)\n    \n    productionPredictions_RF = production_model.predict(production_features_rf)\n    productionPredictions = production_pipeline.predict(production_features)\n    consumptionPredictions = consumption_pipeline.predict(consumption_features)\n\n    prediction = format_outputs([productionPredictions_RF, consumptionPredictions], sample_prediction)\n    env.predict(prediction)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:21:28.268532Z","iopub.execute_input":"2023-12-29T01:21:28.269054Z","iopub.status.idle":"2023-12-29T01:21:29.986473Z","shell.execute_reply.started":"2023-12-29T01:21:28.269023Z","shell.execute_reply":"2023-12-29T01:21:29.985638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"productionPredictions","metadata":{"execution":{"iopub.status.busy":"2023-12-29T01:21:29.98763Z","iopub.execute_input":"2023-12-29T01:21:29.988093Z","iopub.status.idle":"2023-12-29T01:21:29.996125Z","shell.execute_reply.started":"2023-12-29T01:21:29.988066Z","shell.execute_reply":"2023-12-29T01:21:29.994482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}